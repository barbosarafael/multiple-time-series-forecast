{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139dc490-23d0-49ed-863f-ee062f809725",
   "metadata": {},
   "source": [
    "# Modelos de ML\n",
    "\n",
    "**Objetivo**: Criar modelos de ML para a projeção de todas as nossas séries.\n",
    "\n",
    "**Metodologias**: \n",
    "\n",
    "- Regressão Linear\n",
    "- Árvore de decisão\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcfa96b-bb88-4d49-b0fe-37e18b813067",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2557e764-2692-481e-b5aa-acbfe1cfb93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 172 µs (started: 2024-01-03 17:09:21 -03:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06549e4f-9c06-4888-b9d5-6c74c26c4ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.33 s (started: 2024-01-03 17:09:21 -03:00)\n"
     ]
    }
   ],
   "source": [
    "#---- Manipulação de dados:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#---- Modelagem:\n",
    "\n",
    "from hierarchicalforecast.utils import aggregate\n",
    "from mlforecast import MLForecast\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#---- Reconciliação\n",
    "\n",
    "from hierarchicalforecast.methods import BottomUp, TopDown, ERM, OptimalCombination, MinTrace, MiddleOut\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "\n",
    "#---- Visualização\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f788c-d0b4-42e4-bfd4-2fb54590d30b",
   "metadata": {},
   "source": [
    "## 1. Dados: vendas de roupas no varejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93320272-0944-46c3-9a29-e7316bf00f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>item</th>\n",
       "      <th>quantity</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-11-25</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>8</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-11-26</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>9</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-11-27</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>11</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-11-28</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>11</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-11-29</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>10</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    state           item  quantity       region country\n",
       "0  1997-11-25  NewYork  mens_clothing         8  Mid-Alantic     USA\n",
       "1  1997-11-26  NewYork  mens_clothing         9  Mid-Alantic     USA\n",
       "2  1997-11-27  NewYork  mens_clothing        11  Mid-Alantic     USA\n",
       "3  1997-11-28  NewYork  mens_clothing        11  Mid-Alantic     USA\n",
       "4  1997-11-29  NewYork  mens_clothing        10  Mid-Alantic     USA"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.14 s (started: 2024-01-03 17:09:22 -03:00)\n"
     ]
    }
   ],
   "source": [
    "dados = pd.read_csv('https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-hierarchical-forecasting/main/retail-usa-clothing.csv')\n",
    "\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703297e3-1652-4727-9b18-c9ac373696c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 388024 entries, 0 to 388023\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   date      388024 non-null  object\n",
      " 1   state     388024 non-null  object\n",
      " 2   item      388024 non-null  object\n",
      " 3   quantity  388024 non-null  int64 \n",
      " 4   region    388024 non-null  object\n",
      " 5   country   388024 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 17.8+ MB\n",
      "time: 54.8 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303d5ca-61fb-4679-878f-89ac4888edf4",
   "metadata": {},
   "source": [
    "## 2. Modificação nos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cb6b8b-03a1-4768-9e60-214606dadb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.22 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "def clean_data_baseline(df: pd.DataFrame):\n",
    "\n",
    "    #---- 1. Excluindo a variável de country:\n",
    "\n",
    "    df = df\\\n",
    "        .drop(columns = 'country')\n",
    "\n",
    "    #---- 2. Mudando o tipo da variável de date para datetime:\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    #---- 3. Renomeando as variáveis de quantidade de vendas e data:\n",
    "    # date -> ds\n",
    "    # quantity -> y\n",
    "\n",
    "    df = df\\\n",
    "        .rename(columns = {'date': 'ds', \n",
    "                           'quantity': 'y'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296b83a2-cd3a-4920-b992-afd9752364ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>state</th>\n",
       "      <th>item</th>\n",
       "      <th>y</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-11-25</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>8</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-11-26</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>9</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-11-27</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>11</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-11-28</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>11</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-11-29</td>\n",
       "      <td>NewYork</td>\n",
       "      <td>mens_clothing</td>\n",
       "      <td>10</td>\n",
       "      <td>Mid-Alantic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds    state           item   y       region\n",
       "0 1997-11-25  NewYork  mens_clothing   8  Mid-Alantic\n",
       "1 1997-11-26  NewYork  mens_clothing   9  Mid-Alantic\n",
       "2 1997-11-27  NewYork  mens_clothing  11  Mid-Alantic\n",
       "3 1997-11-28  NewYork  mens_clothing  11  Mid-Alantic\n",
       "4 1997-11-29  NewYork  mens_clothing  10  Mid-Alantic"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.5 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "df = clean_data_baseline(df = dados)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3afc572f-4479-45ef-b9c0-2dfe4af461ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 933 µs (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "def format_hierarchical_df(df: pd.DataFrame, cols_hierarchical: list):\n",
    "\n",
    "    #---- 1. Cria uma lista de listas: [[col1], [col1, col2], ..., [col1, col2, coln]]\n",
    "\n",
    "    hier_list = [cols_hierarchical[:i] for i in range(1, len(cols_hierarchical) + 1)]\n",
    "\n",
    "    #---- 2. Aplica a função aggregate que formata os dados em que a lib hierarchical pede\n",
    "\n",
    "    Y_df, S_df, tags = aggregate(df = df, spec = hier_list)\n",
    "\n",
    "    return Y_df, S_df, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999fc534-c03f-4553-a325-1a623f8f9228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 664 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "cols_hierarchical = ['region', 'state', 'item']\n",
    "\n",
    "Y_df, S_df, tags = format_hierarchical_df(df = df, cols_hierarchical = cols_hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98141e69-66c8-4ea6-af22-963af1f42a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-25</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-26</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-27</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-28</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-29</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ds    y\n",
       "unique_id                       \n",
       "EastNorthCentral 1997-11-25  507\n",
       "EastNorthCentral 1997-11-26  504\n",
       "EastNorthCentral 1997-11-27  510\n",
       "EastNorthCentral 1997-11-28  507\n",
       "EastNorthCentral 1997-11-29  513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2009-07-24</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2009-07-25</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2009-07-26</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2009-07-27</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2009-07-28</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ds   y\n",
       "unique_id                                         \n",
       "SouthCentral/Tennessee/womens_shoes 2009-07-24  31\n",
       "SouthCentral/Tennessee/womens_shoes 2009-07-25  30\n",
       "SouthCentral/Tennessee/womens_shoes 2009-07-26  31\n",
       "SouthCentral/Tennessee/womens_shoes 2009-07-27  29\n",
       "SouthCentral/Tennessee/womens_shoes 2009-07-28  30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.46 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "display(Y_df.head())\n",
    "display(Y_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420bec3-4c93-4604-9635-9ca7d0e4dae4",
   "metadata": {},
   "source": [
    "- **Dados de treino: 25/11/1997 a 31/12/2008**\n",
    "- **Dados de validação: 01/01/2009 a 28/07/2009**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99995911-9337-45c4-86b4-1621fbea7353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 493 µs (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(df: pd.DataFrame, dt_start_train: str):\n",
    "\n",
    "    #---- 1. Dados de treino\n",
    "\n",
    "    train = df.query(f'ds < \"{dt_start_train}\"')\n",
    "\n",
    "    #---- 2. Dados de teste:\n",
    "    \n",
    "    valid = df.query(f'ds >= \"{dt_start_train}\"')\n",
    "\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81fb172d-6cbb-42bf-aa05-0ce41449f927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 74.7 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "Y_train_df, Y_valid_df = split_train_test(df = Y_df, dt_start_train = '2009-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b95cd4-22d4-4bb8-9b74-63256f9db6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-25</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-26</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-27</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-28</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EastNorthCentral</th>\n",
       "      <td>1997-11-29</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ds    y\n",
       "unique_id                       \n",
       "EastNorthCentral 1997-11-25  507\n",
       "EastNorthCentral 1997-11-26  504\n",
       "EastNorthCentral 1997-11-27  510\n",
       "EastNorthCentral 1997-11-28  507\n",
       "EastNorthCentral 1997-11-29  513"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2008-12-27</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2008-12-28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2008-12-29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SouthCentral/Tennessee/womens_shoes</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ds   y\n",
       "unique_id                                         \n",
       "SouthCentral/Tennessee/womens_shoes 2008-12-27  31\n",
       "SouthCentral/Tennessee/womens_shoes 2008-12-28  29\n",
       "SouthCentral/Tennessee/womens_shoes 2008-12-29  28\n",
       "SouthCentral/Tennessee/womens_shoes 2008-12-30  31\n",
       "SouthCentral/Tennessee/womens_shoes 2008-12-31  31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.02 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "display(Y_train_df.head())\n",
    "display(Y_train_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956e935-9676-4bb9-af9e-1fe224fab5ff",
   "metadata": {},
   "source": [
    "## 3. Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df862f-9d21-4130-9e21-d569fe1071ce",
   "metadata": {},
   "source": [
    "### 3.1. Fit do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17e5c7d9-a873-4579-a935-81de9f80c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.16 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "#---- Modelos:\n",
    "\n",
    "lin_reg = LinearRegression() # Regressão linear\n",
    "\n",
    "dec_tree = DecisionTreeRegressor(random_state = 19, ) # Árvore de decisão\n",
    "\n",
    "ran_forest = RandomForestRegressor(random_state = 19, n_estimators = 500) # Random Forest\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 19, n_estimators = 500) # LightGBM\n",
    "\n",
    "xgb = XGBRegressor(random_state = 19, n_estimators = 500) # XGBoost\n",
    "\n",
    "models_list = [lin_reg, dec_tree, ran_forest, lgbm, xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37fe06b-8c83-42a7-a2d2-1867178ed95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.88 ms (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "#---- Features de data:\n",
    "\n",
    "from numba import njit\n",
    "from window_ops.expanding import expanding_mean\n",
    "from window_ops.rolling import rolling_mean\n",
    "\n",
    "@njit\n",
    "def rolling_mean_7(x):\n",
    "    return rolling_mean(x, window_size = 7)\n",
    "\n",
    "@njit\n",
    "def rolling_mean_14(x):\n",
    "    return rolling_mean(x, window_size = 14)\n",
    "\n",
    "@njit\n",
    "def rolling_mean_21(x):\n",
    "    return rolling_mean(x, window_size = 21)\n",
    "\n",
    "@njit\n",
    "def rolling_mean_28(x):\n",
    "    return rolling_mean(x, window_size = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de37406e-9ac7-45ea-a243-079b03595474",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#---- Fit:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m MLForecast(models \u001b[38;5;241m=\u001b[39m models_list,\n\u001b[1;32m      4\u001b[0m                    freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                    num_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m                    }\n\u001b[1;32m     15\u001b[0m            )\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munique_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/mlforecast/forecast.py:521\u001b[0m, in \u001b[0;36mMLForecast.fit\u001b[0;34m(self, df, id_col, time_col, target_col, static_features, dropna, keep_last_n, max_horizon, prediction_intervals, fitted, as_numpy)\u001b[0m\n\u001b[1;32m    519\u001b[0m         X \u001b[38;5;241m=\u001b[39m ufp\u001b[38;5;241m.\u001b[39mto_numpy(X)\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m prep\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fitted:\n\u001b[1;32m    523\u001b[0m     fitted_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_fitted_values(\n\u001b[1;32m    524\u001b[0m         base\u001b[38;5;241m=\u001b[39mbase,\n\u001b[1;32m    525\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m         max_horizon\u001b[38;5;241m=\u001b[39mmax_horizon,\n\u001b[1;32m    531\u001b[0m     )\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/mlforecast/forecast.py:291\u001b[0m, in \u001b[0;36mMLForecast.fit_models\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_[name]\u001b[38;5;241m.\u001b[39mappend(clone(model)\u001b[38;5;241m.\u001b[39mfit(Xh, yh))\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_[name] \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documentos/github/multiple-time-series-forecast/venv/lib/python3.10/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23min 4s (started: 2024-01-03 17:09:24 -03:00)\n"
     ]
    }
   ],
   "source": [
    "#---- Fit:\n",
    "\n",
    "model = MLForecast(models = models_list,\n",
    "                   freq = 'D',\n",
    "                   num_threads = 6,\n",
    "                   lags = [1, 7, 14, 21, 28, 30], \n",
    "                   date_features = ['dayofweek', 'month', 'year', 'quarter', 'day', 'week'],\n",
    "                   lag_transforms = {\n",
    "                       1: [expanding_mean],\n",
    "                       7: [rolling_mean_7],\n",
    "                       14: [rolling_mean_14],\n",
    "                       21: [rolling_mean_21],\n",
    "                       28: [rolling_mean_28],\n",
    "                   }\n",
    "           )\n",
    "\n",
    "model.fit(Y_train_df.reset_index(), id_col = 'unique_id', time_col = 'ds', target_col = 'y', fitted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9b2d6-7201-4685-8354-34b3082bc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.preprocess(Y_train_df.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb72d0e-ecbb-484f-8b8c-d4fb7176bf68",
   "metadata": {},
   "source": [
    "### 3.2. Predict para comparação entre os dados de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cbd58-bc75-49ca-ad3e-ac57fe4be259",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_horizon = Y_valid_df.ds.nunique() # Quantidade de dias para a projeção\n",
    "\n",
    "Y_hat_df = model.predict(h = n_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575e300-b7c6-4959-8e8f-0520b8463022",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d3fa2-5d1e-4144-904b-6418cfab1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_fitted_df = model.forecast_fitted_values()\n",
    "\n",
    "display(Y_fitted_df.head())\n",
    "display(Y_fitted_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fd28c5-3a26-4940-87b8-d7fbd25e0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- TO-DO: provar que as somas das projeções dos modelos não batem no Y_hat_df\n",
    "\n",
    "# Y_hat_df\\\n",
    "#     .reset_index()\\\n",
    "#     .assign(\\\n",
    "#         nivel_hierarquia = lambda x: np.where(x['unique_id'].str.count('/') == 0, 1, x['unique_id'].str.count('/') + 1)\n",
    "#     )\\\n",
    "#     .groupby('nivel_hierarquia')[Y_hat_df.select_dtypes(include = 'number').columns]\\\n",
    "#     .sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae3423-5e30-475f-96a4-b4d391dd76af",
   "metadata": {},
   "source": [
    "## 4. Reconciliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b125d36-bd28-437b-93f2-311454fd050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [BottomUp(), \n",
    "               TopDown(method = 'forecast_proportions'),\n",
    "               TopDown(method = 'average_proportions'),\n",
    "               TopDown(method = 'proportion_averages'),\n",
    "               MiddleOut(middle_level = 'region/state', top_down_method = 'forecast_proportions'),\n",
    "               MiddleOut(middle_level = 'region/state', top_down_method = 'average_proportions'),\n",
    "               MiddleOut(middle_level = 'region/state', top_down_method = 'proportion_averages'),\n",
    "               MinTrace(method = 'ols', nonnegative = True),\n",
    "               MinTrace(method = 'wls_struct', nonnegative = True),\n",
    "               MinTrace(method = 'wls_var', nonnegative = True),\n",
    "               MinTrace(method = 'mint_shrink', nonnegative = True),\n",
    "               # MinTrace(method = 'mint_cov', nonnegative = True), # Não descomentar essa linha\n",
    "               OptimalCombination(method = 'ols', nonnegative = True),\n",
    "               OptimalCombination(method = 'wls_struct', nonnegative = True)\n",
    "              ]\n",
    "\n",
    "hrec = HierarchicalReconciliation(reconcilers = reconcilers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e85365-23af-409d-843c-a316342cc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_df = hrec.reconcile(Y_hat_df = Y_hat_df, \n",
    "                          Y_df = Y_fitted_df,\n",
    "                          S = S_df,\n",
    "                          tags = tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fb5de-ea92-49ec-aac3-ddbf853049e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11a889-7423-4664-ac16-7da6167c7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- A soma das projeções nos níveis de hierarquia são diferentes para os modelos sem reconciliação, exceto o Naive\n",
    "\n",
    "# Y_rec_df\\\n",
    "#     .reset_index()\\\n",
    "#     .assign(\\\n",
    "#         nivel_hierarquia = lambda x: np.where(x['unique_id'].str.count('/') == 0, 1, x['unique_id'].str.count('/') + 1)\n",
    "#     )\\\n",
    "#     .groupby('nivel_hierarquia')[Y_rec_df.select_dtypes(include = 'number').columns.tolist()]\\\n",
    "#     .sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766438d-a1f4-4838-87a2-73e3ef4f02dd",
   "metadata": {},
   "source": [
    "## 5. Avaliação das métricas: WMAPE e RMSE\n",
    "\n",
    "- Em nenhum nível a baseline (naive) foi melhor que os modelos testados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2cddfd-d708-4fe8-81e3-ed03a0fbf80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \n",
    "    return np.sqrt(np.mean(np.square(y_true - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e37092b-c5f7-423e-89e4-5cb06e0bd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import HierarchicalEvaluation\n",
    "\n",
    "evaluator = HierarchicalEvaluation(evaluators = [rmse])\n",
    "\n",
    "evaluation = evaluator.evaluate(\n",
    "    Y_hat_df = Y_rec_df,\n",
    "    Y_test_df = Y_valid_df,\n",
    "    tags = tags\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48eb3a-e757-4677-a080-1e725b8d2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Separando os 2 modelos com menor RMSE, excluindo o Naive\n",
    "\n",
    "df_metricas_modelos = pd.melt(evaluation.reset_index(), id_vars = ['level', 'metric'])\\\n",
    "    .sort_values(by = 'value', ascending = True)\\\n",
    "    .assign(\\\n",
    "        is_valid = lambda x: np.where((x['variable'].str.count('/') > 0) | (x['variable'] == 'Naive'), 1, 0)\n",
    "    )\\\n",
    "    .query('is_valid == 1')\\\n",
    "    .groupby(['level', 'metric'])\\\n",
    "    .head(4)\n",
    "\n",
    "#---- Separando os modelos Naive\n",
    "\n",
    "df_metricas_baseline = pd.melt(evaluation.reset_index(), id_vars = ['level', 'metric'])\\\n",
    "    .query('variable == \"Naive\"')\n",
    "\n",
    "#---- Juntando em um único DF\n",
    "\n",
    "df_metricas = pd.concat([df_metricas_modelos, df_metricas_baseline])\\\n",
    "    .reset_index(drop = True)\\\n",
    "    .assign(\\\n",
    "        value = lambda x: x['value'].apply(pd.to_numeric)\n",
    "    )\\\n",
    "    .query('level !=  \"Overall\"')\\\n",
    "    .sort_values(by = ['metric', 'level'])\n",
    "\n",
    "df_metricas['value'] = round(df_metricas['value'], 3)\n",
    "df_metricas['value_format'] = df_metricas['value'].astype(str).str.replace('.', ',')\n",
    "\n",
    "df_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cfb7a5-ac48-418d-b216-61eb5acf1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metricas.variable.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d06a50-3560-4f0d-af8a-d51e167043a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(data_frame = df_metricas, \n",
    "             x = 'level',\n",
    "             y = 'value',\n",
    "             color = 'variable',\n",
    "             barmode = 'group', \n",
    "             text = 'value_format', \n",
    "             template = 'plotly_white')\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis_title = 'RMSE',\n",
    "    xaxis_title = 'Nível da hierarquia',\n",
    "    legend_title = 'Modelo/Reconciliação',\n",
    "    yaxis_visible = False,\n",
    "    bargroupgap = 0.2,\n",
    "    font = dict(\n",
    "        size = 12\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition = 'outside'\n",
    ")\n",
    "\n",
    "fig.update_yaxes(\n",
    "    visible = True,\n",
    "    showticklabels = False, \n",
    "    showgrid = False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e0e76-5098-4a93-a355-2a1e325e31ca",
   "metadata": {},
   "source": [
    "## 6. Dataframe com a tabela final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676d500-2a61-4730-9674-25db2d76882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_df(df_pred: pd.DataFrame, cols_split: str):\n",
    "\n",
    "    df1 = df_pred\\\n",
    "        .reset_index()\\\n",
    "        .assign(\\\n",
    "            nivel_hierarquia = lambda x: np.where(x['unique_id'].str.count('/') == 0, 1, x['unique_id'].str.count('/') + 1)\n",
    "        )\\\n",
    "        .query('nivel_hierarquia == 3')\n",
    "    \n",
    "    df1[cols_split] = df1['unique_id'].str.split(pat = '/', n = len(cols_split), expand = True)\n",
    "    \n",
    "    df1 = df1[cols_split + ['ds'] + df1.select_dtypes(include = 'number').columns.tolist()]\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11275357-d4b2-4e48-a2b1-50dcb03af870",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_final_df(df_pred = Y_rec_df, cols_split = cols_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d7289-01b5-4835-b73e-33268a30bf1d",
   "metadata": {},
   "source": [
    "## 7. Feature importance, a partir dos modelos\n",
    "\n",
    "**Retirado de https://mariofilho.com/como-prever-series-temporais-com-scikit-learn/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2ee4f-568d-4c54-ab90-235227e71ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for mod in list(model.models_.keys()):\n",
    "\n",
    "    if mod == 'LinearRegression':\n",
    "\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "\n",
    "        plt.figure(figsize = (10, 4))\n",
    "\n",
    "        pd.Series(model.models_[mod].feature_importances_, \n",
    "                  index = model.ts.features_order_)\\\n",
    "            .sort_values(ascending = False)\\\n",
    "            .plot\\\n",
    "            .bar(title = f'{mod} Feature Importance',\n",
    "                 xlabel = 'Features', \n",
    "                 ylabel = 'Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0d986-da7c-4990-aefc-2db0f1382252",
   "metadata": {},
   "source": [
    "## 8. Visualizaçẽos das projeções pelos níveis de agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b3039-f146-4c7d-9191-9b03265e7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67168e3-4e9c-43dd-aef6-1dd94ccaf952",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_rec_df.reset_index().merge(Y_valid_df.reset_index(), on = ['unique_id', 'ds'], how = 'left')\\\n",
    "    .query('unique_id == \"SouthCentral/Tennessee/womens_shoes\"')[['ds', 'y', 'LinearRegression/MinTrace_method-ols_nonnegative-True']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9c4cad-63eb-45f0-9a72-d57737bf01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame = Y_rec_df.reset_index().merge(Y_valid_df.reset_index(), on = ['unique_id', 'ds'], how = 'left')\\\n",
    "    .query('unique_id == \"SouthCentral/Tennessee/womens_shoes\"')[['ds', 'y', 'LinearRegression/MinTrace_method-ols_nonnegative-True']], x = 'ds', y = ['y', 'LinearRegression/MinTrace_method-ols_nonnegative-True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff7556-4572-4db2-8f41-b7e008a6948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(\n",
    "    Y_train_df.reset_index().query('ds >= \"2008-01-01\"'), \n",
    "    Y_rec_df.reset_index().merge(Y_valid_df.reset_index(), on = ['unique_id', 'ds'], how = 'left'), \n",
    "    models = ['LinearRegression/MinTrace_method-ols_nonnegative-True'],\n",
    "    plot_random = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a548381-6d5d-421a-bc5e-e8e45cf407c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(evaluation.reset_index(), id_vars = ['level', 'metric'])\\\n",
    "    .sort_values(by = 'value', ascending = True)\\\n",
    "    .assign(\\\n",
    "        is_valid = lambda x: np.where((x['variable'].str.count('/') > 0) | (x['variable'] == 'Naive'), 1, 0)\n",
    "    )\\\n",
    "    .query('is_valid == 1')\\\n",
    "    .groupby(['level', 'metric'])\\\n",
    "    .head(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
